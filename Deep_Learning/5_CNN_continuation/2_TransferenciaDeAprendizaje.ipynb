{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef17655c",
   "metadata": {},
   "source": [
    "# Transfer Learning - Transferencia de Aprendizaje\n",
    "\n",
    "El aprendizaje por transferencia es una técnica de aprendizaje profundo en la que un modelo de red neuronal previamente entrenado (a menudo entrenado en un gran conjunto de datos para una tarea relacionada) se adapta a una tarea nueva y específica. En lugar de entrenar un modelo desde cero, el aprendizaje por transferencia aprovecha el conocimiento adquirido al resolver un problema y lo aplica a un problema diferente pero relacionado.\n",
    "\n",
    "Conceptos importantes:\n",
    "\n",
    "1. **Modelo previamente entrenado**: comenzar con un modelo previamente entrenado que ya haya aprendido características útiles de un gran conjunto de datos. Este modelo ha sido entrenado en una tarea como clasificación de imágenes, detección de objetos o procesamiento del lenguaje natural.\n",
    "\n",
    "2. **Modelo base**: utilizar el modelo previamente entrenado como base o capas iniciales de su nuevo modelo. Estas capas a menudo se denominan \"base convolucional\" en el caso de tareas relacionadas con imágenes.\n",
    "\n",
    "3. **Capas adicionales**: agregar capas adicionales encima de la base previamente entrenada. Estas capas suelen ser específicas de la nueva tarea que desea resolver. Por ejemplo, para una nueva tarea de clasificación de imágenes, agregaría algunas capas densamente conectadas.\n",
    "\n",
    "4. **Entrenamiento**: entrene el modelo combinado en su conjunto de datos específico. Los pesos de las capas previamente entrenadas generalmente se congelan para preservar el conocimiento que ya tienen. Durante el entrenamiento sólo se actualizan los pesos de las capas adicionales.\n",
    "\n",
    "El aprendizaje por transferencia ofrece varias ventajas:\n",
    "\n",
    "1. **Entrenamiento más rápido**: dado que comienza con un modelo previamente entrenado, a menudo necesita menos iteraciones de entrenamiento para lograr un buen rendimiento.\n",
    "\n",
    "2. **Pocos datos de entrenamiento**: puede lograr buenos resultados incluso con un conjunto de datos más pequeño porque el modelo base ya ha aprendido muchas características útiles.\n",
    "\n",
    "3. **Generalización mejorada**: los modelos previamente entrenados han visto una amplia variedad de datos, lo que les ayuda a aprender características que son más generales y transferibles.\n",
    "\n",
    "\n",
    "El aprendizaje por transferencia se utiliza ampliamente en diversos problemas, incluida la visión por computadora, el procesamiento del lenguaje natural e incluso algunas tareas especializadas en el procesamiento de audio y el aprendizaje por refuerzo. Es una herramienta poderosa que ha contribuido significativamente al avance del aprendizaje profundo en aplicaciones del mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223d0e0",
   "metadata": {},
   "source": [
    "## Caso 1:\n",
    "Utilizar un modelo VGG previamente entrenado como extractor de características y agregue sus propias capas densas personalizadas para la clasificación. Ejemplo  usando TensorFlow y Keras:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Cargar el modelo pre-entrenado  VGG16  (Excluir la capa de salida)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Congelar las capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear un nuevo modelo (clasificador)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))  # Asumiendo 10 clases\n",
    "\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# imprimir el resumen\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "Explicación:\n",
    "\n",
    "1. Primero importamos las bibliotecas necesarias y cargamos el modelo VGG16 previamente entrenado sin la capa superior (`include_top=False`).\n",
    "\n",
    "2. Congelamos las capas previamente entrenadas usando un bucle para evitar que se actualicen durante el entrenamiento.\n",
    "\n",
    "3. A continuación, creamos un nuevo modelo secuencial y agregamos el modelo VGG previamente entrenado como primera capa. Luego agregamos una capa `Flatten` para convertir los mapas de características 2D en un vector 1D.\n",
    "\n",
    "4. Agregamos una capa Densa con 256 unidades y activación ReLU, seguida de una capa de `Dropout` para regularización.\n",
    "\n",
    "5. Finalmente, agregamos una capa Densa de salida con activación softmax, asumiendo 10 clases para la clasificación.\n",
    "\n",
    "6. El modelo se compila con un optimizador, una función de pérdida y una métrica para evaluación.\n",
    "\n",
    "Asegúrese de preparar su conjunto de datos para el entrenamiento y la evaluación, y ajuste la forma de entrada y la cantidad de clases de salida según su tarea específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive',force_remount=True)\n",
    "#root_dir = '/content/gdrive/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ca5d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] datos cargados y redimensionados a la forma: num imagenes x filas x columnas x 3 canales\n",
      " \n",
      "Etiquetas o clases: \n",
      " [0 1 2 3 4 5 6 7 8 9] \n",
      "Datos por clase \n",
      " [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
      "Train set: (60000, 48, 48, 3), Test set: (10000, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot       as plt\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "root_dir = ''\n",
    "\n",
    "X_train, y_train = loadlocal_mnist(\n",
    "        images_path=root_dir+'MNIST/train-images-idx3-ubyte', \n",
    "        labels_path=root_dir+'MNIST/train-labels-idx1-ubyte')\n",
    "\n",
    "X_test, y_test = loadlocal_mnist(\n",
    "        images_path=root_dir+'MNIST/t10k-images-idx3-ubyte', \n",
    "        labels_path=root_dir+'MNIST/t10k-labels-idx1-ubyte')\n",
    "\n",
    "#organizar como arreglo de matrices\n",
    "X_train = X_train.reshape(60000,28,28)\n",
    "X_test = X_test.reshape(10000,28,28)\n",
    "\n",
    "#ajustar para que sea de 3 canales\n",
    "X_train = np.repeat(X_train[:, :,:, np.newaxis], 3, axis=3)\n",
    "X_test  = np.repeat(X_test[:, :,:, np.newaxis], 3, axis=3)\n",
    "#cambiar dimensiones 48x48\n",
    "new_dim = (48,48)\n",
    "X_train = np.array([cv2.resize(image, new_dim) for image in X_train])\n",
    "X_test = np.array([cv2.resize(image, new_dim) for image in X_test])\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] datos cargados y redimensionados a la forma: num imagenes x filas x columnas x 3 canales\")\n",
    "labels,count_class = np.unique(y_train,return_counts=True)\n",
    "print(' \\nEtiquetas o clases: \\n %s \\nDatos por clase \\n %s' % (labels,count_class))\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "num_classes = labels.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5772bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHIAAAGuCAYAAAD8jyEfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAABBXklEQVR4nO3dfXRV9Z0v/k9ISEAgiYAkIODQqjyoYMWK6YPXB8aUYbrsyKzVdrwtbW279EZXBada7nKo2s7Fsbc+tai9U0ecdXWozKr2Kq2WguC1BqpRWtSRqoMNFhIsSiIPSSDZvz/641zDw05CgJMtr9daZy1y3t+zz/d8OQk7b/bZuyBJkiQAAAAA6PP65XsCAAAAAHSPIgcAAAAgIxQ5AAAAABmhyAEAAADICEUOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZERRviewr46Ojti0aVMMGTIkCgoK8j0dAI6iJEnivffei1GjRkW/fv6vgWyyLwMA9FRP9oOPWJGzcOHC+N73vhcNDQ0xZcqU+MEPfhDnnHNOl4/btGlTjBkz5khNC4AM2LhxY4wePTrf04BDYl8GADhU3dkPPiJFzk9+8pOYO3du3HvvvTFt2rS44447orq6OtavXx8jRoxIfeyQIUOOxJQAyBD/FpBle9+/GzdujNLS0jzPBgDIgubm5hgzZky39oMLkiRJDvcEpk2bFh/96Efjhz/8YUT8+RDjMWPGxNVXXx3f+ta3Uh/b3NwcZWVlh3tKAGRIU1OTX4DJrL37Mt7HAEB39WT/4bCfgKCtrS3q6upi+vTp/+9J+vWL6dOnR21t7X7jW1tbo7m5udMNAAAAgP0d9iLnT3/6U7S3t0dFRUWn+ysqKqKhoWG/8QsWLIiysrLczWfKAQAAAA4s75cEmTdvXjQ1NeVuGzduzPeUAAAAAPqkw36y4+HDh0dhYWE0NjZ2ur+xsTEqKyv3G19SUhIlJSWHexoAAAAAHziH/Yic4uLimDp1aixfvjx3X0dHRyxfvjyqqqoO99MBAAAAHDOOyOXH586dG7Nnz46zzz47zjnnnLjjjjtix44d8eUvf/lIPB0AAADAMeGIFDmf/exn4+2334758+dHQ0NDnHnmmfHEE0/sdwJkAAAAALqvIEmSJN+TeL+9104H4NjV1NQUpaWl+Z4GHJK9+zLexwBAd/Vk/yHvV60CAAAAoHsUOQBAn3fjjTdGQUFBp9uECRNyeUtLS9TU1MSwYcNi8ODBMWvWrP2uoFlfXx8zZ86M4447LkaMGBHf/OY3Y8+ePZ3GrFy5Ms4666woKSmJk08+ORYtWnQ0Xh4AQLcpcgCATDjttNNi8+bNudszzzyTy+bMmROPPfZYLFmyJFatWhWbNm2KSy+9NJe3t7fHzJkzo62tLZ599tl44IEHYtGiRTF//vzcmA0bNsTMmTPjggsuiLVr18Y111wTX/3qV+PJJ588qq8TACCNc+QA0Oc4twj7uvHGG+PRRx+NtWvX7pc1NTXFCSecEA899FD87d/+bUREvPrqqzFx4sSora2Nc889N37xi1/EX//1X8emTZtyF1+499574/rrr4+33347iouL4/rrr4+lS5fGSy+9lNv25z73udi2bVs88cQT3Z6rc+QAAD3lHDkAwAfOa6+9FqNGjYoPfehDcdlll0V9fX1ERNTV1cXu3btj+vTpubETJkyIsWPHRm1tbURE1NbWxhlnnNHpCprV1dXR3NwcL7/8cm7M+7exd8zebRxMa2trNDc3d7oBABwpihwAoM+bNm1aLFq0KJ544om45557YsOGDfHJT34y3nvvvWhoaIji4uIoLy/v9JiKiopoaGiIiIiGhoZOJc7efG+WNqa5uTl27dp10LktWLAgysrKcrcxY8b09uUCABxUUb4nAADQlRkzZuT+PHny5Jg2bVqcdNJJ8fDDD8fAgQPzOLOIefPmxdy5c3NfNzc3K3MAgCPGETkAQOaUl5fHqaeeGq+//npUVlZGW1tbbNu2rdOYxsbGqKysjIiIysrK/a5itffrrsaUlpamlkUlJSVRWlra6QYAcKQocgCAzNm+fXu88cYbMXLkyJg6dWr0798/li9fnsvXr18f9fX1UVVVFRERVVVVsW7dutiyZUtuzLJly6K0tDQmTZqUG/P+bewds3cbfclffGvpfjcA4NigyAEA+ry///u/j1WrVsWbb74Zzz77bPzN3/xNFBYWxuc///koKyuLyy+/PObOnRtPPfVU1NXVxZe//OWoqqqKc889NyIiLr744pg0aVJ84QtfiN/+9rfx5JNPxg033BA1NTVRUlISERFXXHFF/Od//mdcd9118eqrr8bdd98dDz/8cMyZMyefLx0AoBPnyAEA+ry33norPv/5z8fWrVvjhBNOiE984hOxevXqOOGEEyIi4vbbb49+/frFrFmzorW1Naqrq+Puu+/OPb6wsDAef/zxuPLKK6OqqioGDRoUs2fPjptvvjk3Zty4cbF06dKYM2dO3HnnnTF69Oj48Y9/HNXV1Uf99QIAHExBkiRJvifxfnuvnQ7Asaupqcl5RsisvfsyR/J9fKCPUr15y8wj8lwAwJHXk/0HH60CAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgIxQ5AAAAABmhyAEAAADICEUOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZIQiBwAAACAjFDkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkhCIHAAAAICMUOQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgIxQ5AAAAABmhyAEAAADICEUOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZIQiBwAAACAjFDkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkhCIHAAAAICMUOQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgIxQ5AAAAABmhyAEAAADIiB4XOU8//XR8+tOfjlGjRkVBQUE8+uijnfIkSWL+/PkxcuTIGDhwYEyfPj1ee+21wzVfAAAAgGNWj4ucHTt2xJQpU2LhwoUHzG+99da466674t577401a9bEoEGDorq6OlpaWno9WQAAAIBjWVFPHzBjxoyYMWPGAbMkSeKOO+6IG264IS655JKIiPjXf/3XqKioiEcffTQ+97nP9W62AAAAAMeww3qOnA0bNkRDQ0NMnz49d19ZWVlMmzYtamtrD/iY1tbWaG5u7nQDAAAAYH+HtchpaGiIiIiKiopO91dUVOSyfS1YsCDKyspytzFjxhzOKQEAAAB8YOT9qlXz5s2Lpqam3G3jxo35nhIAAABAn3RYi5zKysqIiGhsbOx0f2NjYy7bV0lJSZSWlna6AQCkueWWW6KgoCCuueaa3H0tLS1RU1MTw4YNi8GDB8esWbP22yepr6+PmTNnxnHHHRcjRoyIb37zm7Fnz55OY1auXBlnnXVWlJSUxMknnxyLFi06Cq8IAKB7DmuRM27cuKisrIzly5fn7mtubo41a9ZEVVXV4XwqAOAY9dxzz8WPfvSjmDx5cqf758yZE4899lgsWbIkVq1aFZs2bYpLL700l7e3t8fMmTOjra0tnn322XjggQdi0aJFMX/+/NyYDRs2xMyZM+OCCy6ItWvXxjXXXBNf/epX48knnzxqrw8AIE2Pr1q1ffv2eP3113Nfb9iwIdauXRtDhw6NsWPHxjXXXBPf/e5345RTTolx48bFP/zDP8SoUaPiM5/5zOGcNxxUcXFxaj548ODUvF+/3vWbHR0dvXp8//79U/P29vYut9Ha2tqrvK2trcvnAMiH7du3x2WXXRb//M//HN/97ndz9zc1NcV9990XDz30UFx44YUREXH//ffHxIkTY/Xq1XHuuefGL3/5y3jllVfiV7/6VVRUVMSZZ54Z3/nOd+L666+PG2+8MYqLi+Pee++NcePGxfe///2IiJg4cWI888wzcfvtt0d1dXVeXjMAwPv1+DfW559/Pj7ykY/ERz7ykYiImDt3bnzkIx/J/W/WddddF1dffXV8/etfj49+9KOxffv2eOKJJ2LAgAGHd+YAwDGnpqYmZs6c2ekKmRERdXV1sXv37k73T5gwIcaOHZu7cmZtbW2cccYZnS7KUF1dHc3NzfHyyy/nxuy77erq6oNefTPCFTgBgKOrx0fknH/++ZEkyUHzgoKCuPnmm+Pmm2/u1cQAAN5v8eLF8cILL8Rzzz23X9bQ0BDFxcVRXl7e6f73XzmzoaHhgFfW3JuljWlubo5du3bFwIED93vuBQsWxE033XTIrwsAoCfyftUqAICubNy4Mb7xjW/Egw8+2OeO8nUFTgDgaFLkAAB9Xl1dXWzZsiXOOuusKCoqiqKioli1alXcddddUVRUFBUVFdHW1hbbtm3r9Lj3XzmzsrLygFfW3JuljSktLT3g0TgRrsAJABxdihwAoM+76KKLYt26dbF27drc7eyzz47LLrss9+f+/ft3unLm+vXro76+PnflzKqqqli3bl1s2bIlN2bZsmVRWloakyZNyo15/zb2jnH1TQCgr+jxOXIAAI62IUOGxOmnn97pvkGDBsWwYcNy919++eUxd+7cGDp0aJSWlsbVV18dVVVVce6550ZExMUXXxyTJk2KL3zhC3HrrbdGQ0ND3HDDDVFTUxMlJSUREXHFFVfED3/4w7juuuviK1/5SqxYsSIefvjhWLp06dF9wQAAB6HIAQA+EG6//fbo169fzJo1K1pbW6O6ujruvvvuXF5YWBiPP/54XHnllVFVVRWDBg2K2bNnd7pAw7hx42Lp0qUxZ86cuPPOO2P06NHx4x//2KXHAYA+oyBJuwRVHjQ3N0dZWVm+p0GGjRgxIjU/44wzUvODnQNhr66+ZVpaWlLzgoKC1HzYsGGp+Y4dO1LziIhNmzal5m+99VZq/v6PHUA+NDU1Oc8ImbV3X+ZIvo//4lv7HyH05i0zj8hzAQBHXk/2H5wjBwAAACAjFDkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIwoyvcE+qKiovRlGT58eGpeVlaWmg8aNCg1Hzp0aK+e/1g3bNiw1Hz8+PGp+YABA3r1/C0tLal5QUFBal5eXp6a79q1q8s5bNmyJTXfvHlzav7222+n5jt37kzNGxsbU/PXXnstNd++fXtqvmfPntQcAADgg8oROQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjFDkAAAAAGREUb4n0BeVlJSk5qecckpqPn78+NT8xBNPTM3PPPPM1Pyss85KzY91xcXFqfmgQYNS88LCwtQ8SZLUvKOjIzXvSv/+/VPz9vb2LrfR1taWmre2tqbmO3bsSM03b96cmj/zzDOp+QMPPJCab9y4MTXfs2dPag4AAPBB5YgcAAAAgIxQ5AAAAABkhCIHAAAAICMUOQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMqIo3xPIh4kTJ6bmU6ZMSc0//vGPp+annHJKal5aWpqaV1RUpObDhw9PzY91/fql95P9+/dPzQsKCnr1/EmS9OrxXT1/d7ZfXFycmg8cODA1Hzx4cGo+aNCg1Ly9vT0137VrV2r+zDPPpOa/+c1vUvPW1tbUfPfu3ak5AABAX+WIHAAAAICMUOQAAAAAZIQiBwAAACAjFDkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADKiKN8TyIeJEyem5jNnzkzNP/7xj6fmo0ePTs07OjpS864kSdKrx+fbnj17UvPdu3f3Km9vb+/xnLKksLCwyzH9+/dPzUtKSlLzAQMGpObHHXdcal5cXJyaDx48ODUvKChIzRsaGnqVb9u2LTXv6nss69+DAABAdjkiBwAAACAjFDkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIwoyvcE8uHEE09MzU8//fTUvLy8PDVva2tLzbdu3Zqat7a2pubt7e2peV/X2NiYmm/atCk137BhQ2q+bdu2nk4pU4YOHdrlmNGjR6fmp556amo+bty41HzIkCGp+aBBg3q1/QsuuCA1HzBgQGr+i1/8IjV/4YUXUvNdu3al5ln/HgQAALLLETkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkRFG+J5AP7777bmr+5ptvpubvvfdeat7W1paa19fXp+bbt29PzXfv3p2a93WNjY2p+aZNm1LzDRs2pObbtm3r6ZQyZejQoV2OGT16dGr+hz/8ITU//fTTe5WPHDkyNS8rK0vNJ06cmJoPHDgwNf/jH/+Ymjc0NKTmb731Vmq+c+fO1BwAAOBIcUQOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZIQiBwAAACAjFDkAAAAAGVGU7wnkw69//evUfPPmzal5ZWVlat7a2pqar1+/PjVvbm5Ozdva2lLzvm7Pnj2p+e7du1Pzrl5/R0dHj+eUJW+++WaXY9atW5ea19XVpeYTJkxIzb/whS+k5gMHDkzNTzjhhNT8+OOPT81LSkpS84985COp+aZNm1Lzd999NzXfuXNnag4AAHCkOCIHAAAAICMUOQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAoM+75557YvLkyVFaWhqlpaVRVVUVv/jFL3J5S0tL1NTUxLBhw2Lw4MExa9asaGxs7LSN+vr6mDlzZhx33HExYsSI+OY3vxl79uzpNGblypVx1llnRUlJSZx88smxaNGio/HyAAC6ragngxcsWBA//elP49VXX42BAwfGxz72sfinf/qnGD9+fG5MS0tLXHvttbF48eJobW2N6urquPvuu6OiouKwT/5QbdmyJTXftWtXal5fX5+at7e39+r5W1paUvN9dzqhp9ra2lLzrt7DtbW1qfngwYNT84997GOp+ZAhQ1Lz4447LjU//fTTU/N9f7nb129/+9vU/O23307NgcNv9OjRccstt8Qpp5wSSZLEAw88EJdcckm8+OKLcdppp8WcOXNi6dKlsWTJkigrK4urrroqLr300vj1r38dEX/+uTZz5syorKyMZ599NjZv3hxf/OIXo3///vE//sf/iIiIDRs2xMyZM+OKK66IBx98MJYvXx5f/epXY+TIkVFdXZ3Plw8AkNOjI3JWrVoVNTU1sXr16li2bFns3r07Lr744tixY0duzJw5c+Kxxx6LJUuWxKpVq2LTpk1x6aWXHvaJAwDHjk9/+tPxV3/1V3HKKafEqaeeGv/4j/8YgwcPjtWrV0dTU1Pcd999cdttt8WFF14YU6dOjfvvvz+effbZWL16dURE/PKXv4xXXnkl/vf//t9x5plnxowZM+I73/lOLFy4MFdu33vvvTFu3Lj4/ve/HxMnToyrrroq/vZv/zZuv/32fL50AIBOelTkPPHEE/GlL30pTjvttJgyZUosWrQo6uvro66uLiKiWztSAAC90d7eHosXL44dO3ZEVVVV1NXVxe7du2P69Om5MRMmTIixY8fmjiCsra2NM844o9MRwtXV1dHc3Bwvv/xybsz7t7F3TFdHIQIAHE29OkdOU1NTREQMHTo0IqJbO1IAAIdi3bp1MXjw4CgpKYkrrrgiHnnkkZg0aVI0NDREcXFxlJeXdxpfUVERDQ0NERHR0NCw38e8937d1Zjm5ubUj123trZGc3NzpxsAwJHSo3PkvF9HR0dcc8018fGPfzx3Poru7Ejtq7W1NVpbW3Nf2/kBAA5k/PjxsXbt2mhqaop///d/j9mzZ8eqVavyPa1YsGBB3HTTTfmeBgBwjDjkI3JqamripZdeisWLF/dqAgsWLIiysrLcbcyYMb3aHgDwwVRcXBwnn3xyTJ06NRYsWBBTpkyJO++8MyorK6OtrS22bdvWaXxjY2NUVlZGRERlZeV+Jzrf+3VXY0pLS2PgwIEHnde8efOiqakpd9u4cWNvXyoAwEEdUpFz1VVXxeOPPx5PPfVUjB49Ond/d3ak9mXnBwA4FB0dHdHa2hpTp06N/v37x/Lly3PZ+vXro76+PqqqqiIioqqqKtatW9fpypHLli2L0tLSmDRpUm7M+7exd8zebRxMSUlJ7rLoe28AAEdKjz5alSRJXH311fHII4/EypUrY9y4cZ3y9+9IzZo1KyL235HaV0lJSZSUlBzi9AGAY8G8efNixowZMXbs2HjvvffioYceipUrV8aTTz4ZZWVlcfnll8fcuXNj6NChUVpaGldffXVUVVXFueeeGxERF198cUyaNCm+8IUvxK233hoNDQ1xww03RE1NTW4/5Iorrogf/vCHcd1118VXvvKVWLFiRTz88MOxdOnSfL50AIBOelTk1NTUxEMPPRQ/+9nPYsiQIbnz3pSVlcXAgQO7tSPVF7z/cumHkh/sfD+QFTt37kzNN2/enJqvWbMmNR8+fHhqftZZZ6XmQ4YMSc0LCwtT8wkTJqTm+x41uK8lS5ak5sDRt2XLlvjiF78YmzdvjrKyspg8eXI8+eST8Zd/+ZcREXH77bdHv379YtasWdHa2hrV1dVx99135x5fWFgYjz/+eFx55ZVRVVUVgwYNitmzZ8fNN9+cGzNu3LhYunRpzJkzJ+68884YPXp0/PjHP47q6uqj/noBAA6mR0XOPffcExER559/fqf777///vjSl74UEV3vSAEA9NR9992Xmg8YMCAWLlwYCxcuPOiYk046KX7+85+nbuf888+PF1988ZDmCABwNPT4o1Vd6c6OFAAAAAA9d8hXrQIAAADg6FLkAAAAAGSEIgcAAAAgIxQ5AAAAABmhyAEAAADIiB5dtQqgO7pzhTsAAAB6zhE5AAAAABmhyAEAAADICEUOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZERRvicAHH2DBw9OzYcPH56aDx06NDUfNGhQal5QUJCa91a/fukddVFR+o++AQMGpOYlJSWpeWtra2oOAABwqByRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgIxQ5AAAAABmhyAEAAADICEUOAAAAQEYU5XsCwNE3bty41Hzy5Mmp+Yc+9KHUfOzYsal5cXFxat5bhYWFqflxxx2Xmo8cOTI1Hzp0aGre2NiYmnd0dKTmAAAAB+OIHAAAAICMUOQAAAAAZIQiBwAAACAjFDkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEUX5ngAcboWFhal5//79U/Pjjz8+NT/hhBNS88rKytS8vLw8NT8aJkyYkJqPHz8+NR82bFhqfuKJJ6bmxcXFqXlXCgoKUvOiovQfbSNGjEjNL7zwwtS8ra0tNX/yySdT846OjtQcAADgYByRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgIxQ5AAAAABmhyAEAAADICEUOAAAAQEYU5XsCcLgVFaW/rYcMGZKajx8/PjX/6Ec/mpqfd955qfmECRNS86OhrKwsNe9qjfr1S++Ae5v3VlfvgdGjR6fmn//851Pz9vb21HzFihWp+e7du1NzAACAg3FEDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgIxQ5AAAAABlRlO8JcOwZPnx4r/Ly8vLUfPTo0an5qaeempqffPLJqfmHP/zh1Hzs2LGp+bBhw1Lzo6G4uLhXedbt2rUrNX/99ddT87feeis17+jo6PGcAAAAusMROQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjFDkAAAAAGREUb4nwNFXUFCQmhcWFqbmAwYMSM0HDRqUmp9yyim9ykeNGpWajx8/PjWfOnVqaj5y5MjUvLy8PDXv6Og4ovnhsGvXrtR827ZtqXmSJKl5//79U/Ou3iNFRek/mrp6j3Zl586dqfnvf//71Ly+vj41Pxp/hwAAwLHJETkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkRFG+J8DRV1SU/tdeXl6emp9xxhmp+XnnnZeaT5gwITUfN25caj5w4MDUfMiQIan58ccfn5oPGDAgNU+SJDXfvn17ar5jx47UvLW1NTXv6OhIzbvjhRdeSM1ffvnl1Ly9vT01HzNmTGr+iU98IjUfNWpUal5WVpaad6Wr+Xf1d7hr167UvKv3CNBzCxYsiJ/+9Kfx6quvxsCBA+NjH/tY/NM//VOMHz8+N6alpSWuvfbaWLx4cbS2tkZ1dXXcfffdUVFRkRtTX18fV155ZTz11FMxePDgmD17dixYsKDTv40rV66MuXPnxssvvxxjxoyJG264Ib70pS8dzZcLAHBQjsgBAPq8VatWRU1NTaxevTqWLVsWu3fvjosvvrhTOT5nzpx47LHHYsmSJbFq1arYtGlTXHrppbm8vb09Zs6cGW1tbfHss8/GAw88EIsWLYr58+fnxmzYsCFmzpwZF1xwQaxduzauueaa+OpXvxpPPvnkUX29AAAH44gcAKDPe+KJJzp9vWjRohgxYkTU1dXFeeedF01NTXHffffFQw89FBdeeGFERNx///0xceLEWL16dZx77rnxy1/+Ml555ZX41a9+FRUVFXHmmWfGd77znbj++uvjxhtvjOLi4rj33ntj3Lhx8f3vfz8iIiZOnBjPPPNM3H777VFdXX3UXzcAwL4ckQMAZE5TU1NERAwdOjQiIurq6mL37t0xffr03JgJEybE2LFjo7a2NiIiamtr44wzzuj0Uavq6upobm7OfaS0tra20zb2jtm7DQCAfHNEDgCQKR0dHXHNNdfExz/+8Tj99NMjIqKhoSGKi4v3O89bRUVFNDQ05Ma8v8TZm+/N0sY0NzfHrl27DniettbW1k7nN2tubu7dCwQASOGIHAAgU2pqauKll16KxYsX53sqEfHnEzGXlZXlbl2d8B0AoDcUOQBAZlx11VXx+OOPx1NPPRWjR4/O3V9ZWRltbW2xbdu2TuMbGxujsrIyN6axsXG/fG+WNqa0tPSgV02cN29eNDU15W4bN27s1WsEAEijyAEA+rwkSeKqq66KRx55JFasWBHjxo3rlE+dOjX69+8fy5cvz923fv36qK+vj6qqqoiIqKqqinXr1sWWLVtyY5YtWxalpaUxadKk3Jj3b2PvmL3bOJCSkpIoLS3tdAMAOFJ6dI6ce+65J+6555548803IyLitNNOi/nz58eMGTMiIqKlpSWuvfbaWLx4cbS2tkZ1dXXcfffd+33WnN4pKChIzYcPH56a7/1fx4PZd+d4X+eee25qvu9JIvf1/v9BPZBhw4al5h0dHan5+y9FeyD7/k/rvt5/noMDaWtr69X2t27dmppv3749Nd+zZ09q3h0vvPBCar73pJ8H097enpqfccYZqfkpp5ySmh9//PGpeVlZWWre1fx27dqVmu89V8bBdPV3mCRJag70XE1NTTz00EPxs5/9LIYMGZL7Pi0rK4uBAwdGWVlZXH755TF37twYOnRolJaWxtVXXx1VVVW5f7cuvvjimDRpUnzhC1+IW2+9NRoaGuKGG26ImpqaKCkpiYiIK664In74wx/GddddF1/5yldixYoV8fDDD8fSpUvz9toBAN6vR0fkjB49Om655Zaoq6uL559/Pi688MK45JJLcr/0zZkzJx577LFYsmRJrFq1KjZt2hSXXnrpEZk4AHDsuOeee6KpqSnOP//8GDlyZO72k5/8JDfm9ttvj7/+67+OWbNmxXnnnReVlZXx05/+NJcXFhbG448/HoWFhVFVVRX/9b/+1/jiF78YN998c27MuHHjYunSpbFs2bKYMmVKfP/7348f//jHLj0OAPQZPToi59Of/nSnr//xH/8x7rnnnli9enWMHj067rvvvnjooYfiwgsvjIiI+++/PyZOnBirV6/u8igOAICD6c6RbgMGDIiFCxfGwoULDzrmpJNOip///Oep2zn//PPjxRdf7PEcAQCOhkM+R057e3ssXrw4duzYEVVVVVFXVxe7d+/u9LGaCRMmxNixY6O2tvag22ltbY3m5uZONwAAAAD21+MiZ926dTF48OAoKSmJK664Ih555JGYNGlSNDQ0RHFxcZSXl3caX1FRkXq+CZfsBAAAAOieHhc548ePj7Vr18aaNWviyiuvjNmzZ8crr7xyyBNwyU4AAACA7unROXIiIoqLi+Pkk0+OiD9f6vO5556LO++8Mz772c9GW1tbbNu2rdNROY2NjalXSSopKcldKQIAAACAgzvkc+Ts1dHREa2trTF16tTo379/LF++PJetX78+6uvro6qqqrdPAwAAAHDM69EROfPmzYsZM2bE2LFj47333ouHHnooVq5cGU8++WSUlZXF5ZdfHnPnzo2hQ4dGaWlpXH311VFVVeWKVYdZYWFhaj5x4sTUvKtirat8/Pjxqfno0aNT84KCgtS8tbU1NW9paUnN33zzzdQ87eTbEX8+iixNU1NTr55/06ZNqfm7776bmre1taXm3bFr167UvKs17kpZWVlqvn379tR8z549vXr+rh6/bdu21Py1115Lzd96663UvKOjIzUHAAA4VD0qcrZs2RJf/OIXY/PmzVFWVhaTJ0+OJ598Mv7yL/8yIiJuv/326NevX8yaNStaW1ujuro67r777iMycQAAAIBjTY+KnPvuuy81HzBgQCxcuDAWLlzYq0kBAAAAsL9enyMHAAAAgKNDkQMAAACQEYocAAAAgIxQ5AAAAABkhCIHAAAAICN6dNUq+oZ+/dL7t8rKytR8woQJqfn48eNT89LS0tS8oaEhNd+wYUNq/oc//CE1f/vtt1PzjRs3puZvvPFGat7c3Jya79q1KzV/5513UvNt27al5jt37kzN29vbU/PDobCwMDUfMmRIr/LBgwen5sXFxal5kiSpeVdr1NXfYWNjY2r+7rvvpuZdzQ8AAOBQOSIHAAAAICMUOQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjCjK9wTouYKCgtS8rKwsNT/hhBN69fjt27en5r/73e9S86effjo1f/bZZ1PzN954IzV/9913U3O6VlhYmJoPGzYsNR85cmSvHn/cccel5l3Zs2dPar5z587UfOvWral5c3Nzj+cEAABwODgiBwAAACAjFDkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIwoyvcE6Lk9e/ak5r/5zW9S87a2ttT8rbfeSs23bt2amq9atSo1/+Mf/5iaNzY2puY7d+5Mzem9wsLC1LysrCw1Hzp0aGpeWlqampeUlKTmHR0dqfnmzZtT8zfffDM1b2lpSc0BAADyxRE5AAAAABmhyAEAAADICEUOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZERRvidAz3V0dKTmv//971Pzpqam1Ly5uTk1/9Of/pSa19bWpuZ79uxJzcm/wsLC1Hzo0KGp+fDhw1PzQYMG9er529raUvM//OEPqXlX3yM7d+5MzQEAAPLFETkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkRFG+J0DPJUmSmre2tqbmDQ0NqfkzzzyTmu/evTs1b29vT83p+4qK0n80jBgxIjWvqKjo1fb37NmTmm/fvj01f+mll1LzF154ITVvbm5OzQEAAPLFETkAAAAAGaHIAQAAAMgIRQ4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkRFG+J8Dh19HRkZq3tLT0Kif7TjvttNT8zDPPTM0/8YlPpOannnpqal5SUpKaNzc3p+b19fWp+e9///vU/I033kjNd+3alZoDAADkiyNyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkhCIHAAAAICMUOQAAAAAZocgBAAAAyIiifE8AOPouvPDC1PwrX/lKaj5y5MjUvLy8PDXv379/ar5x48bU/NVXX03NX3vttdR806ZNqXlHR0dqDgAAkC+OyAEAAADICEUOANDnPf300/HpT386Ro0aFQUFBfHoo492ypMkifnz58fIkSNj4MCBMX369P2OznvnnXfisssui9LS0igvL4/LL788tm/f3mnM7373u/jkJz8ZAwYMiDFjxsStt956pF8aAECPKHIAgD5vx44dMWXKlFi4cOEB81tvvTXuuuuuuPfee2PNmjUxaNCgqK6ujpaWltyYyy67LF5++eVYtmxZPP744/H000/H17/+9Vze3NwcF198cZx00klRV1cX3/ve9+LGG2+M//W//tcRf30AAN3lHDkAQJ83Y8aMmDFjxgGzJEnijjvuiBtuuCEuueSSiIj413/916ioqIhHH300Pve5z8V//Md/xBNPPBHPPfdcnH322RER8YMf/CD+6q/+Kv7n//yfMWrUqHjwwQejra0t/uVf/iWKi4vjtNNOi7Vr18Ztt93WqfABAMgnR+QAAJm2YcOGaGhoiOnTp+fuKysri2nTpkVtbW1ERNTW1kZ5eXmuxImImD59evTr1y/WrFmTG3PeeedFcXFxbkx1dXWsX78+3n333YM+f2trazQ3N3e6AQAcKYocACDTGhoaIiKioqKi0/0VFRW5rKGhIUaMGNEpLyoqiqFDh3Yac6BtvP85DmTBggVRVlaWu40ZM6Z3LwgAIIUiBwCgF+bNmxdNTU2528aNG/M9JQDgA8w5cuAYVFpamprv+z/S+xoyZEhq3q9fekfc2tqamv/nf/5nav5//+//Tc03b96cmnd0dKTmQLZUVlZGRERjY2OMHDkyd39jY2OceeaZuTFbtmzp9Lg9e/bEO++8k3t8ZWVlNDY2dhqz9+u9Yw6kpKQkSkpKev06AAC6wxE5AECmjRs3LiorK2P58uW5+5qbm2PNmjVRVVUVERFVVVWxbdu2qKury41ZsWJFdHR0xLRp03Jjnn766di9e3duzLJly2L8+PFx/PHHH6VXAwCQTpEDAPR527dvj7Vr18batWsj4s8nOF67dm3U19dHQUFBXHPNNfHd7343/s//+T+xbt26+OIXvxijRo2Kz3zmMxERMXHixPjUpz4VX/va1+I3v/lN/PrXv46rrroqPve5z8WoUaMiIuLv/u7vori4OC6//PJ4+eWX4yc/+UnceeedMXfu3Dy9agCA/floFQDQ5z3//PNxwQUX5L7eW67Mnj07Fi1aFNddd13s2LEjvv71r8e2bdviE5/4RDzxxBMxYMCA3GMefPDBuOqqq+Kiiy6Kfv36xaxZs+Kuu+7K5WVlZfHLX/4yampqYurUqTF8+PCYP3++S48DAH2KIgcA6PPOP//8SJLkoHlBQUHcfPPNcfPNNx90zNChQ+Ohhx5KfZ7Jkyd3eR4uAIB88tEqAAAAgIxQ5AAAAABkhCIHAAAAICN6dY6cW265JebNmxff+MY34o477oiIiJaWlrj22mtj8eLF0draGtXV1XH33XdHRUXF4ZgvHPOKirr+ti0pKUnNS0tLe5V3NYfW1tbUfOvWran5q6++mpqvWbMmNX/77bdTcwAAgKw65CNynnvuufjRj34UkydP7nT/nDlz4rHHHoslS5bEqlWrYtOmTXHppZf2eqIAAAAAx7pDKnK2b98el112WfzzP/9zHH/88bn7m5qa4r777ovbbrstLrzwwpg6dWrcf//98eyzz8bq1asP26QBAAAAjkWHVOTU1NTEzJkzY/r06Z3ur6uri927d3e6f8KECTF27Niora094LZaW1ujubm50w0AAACA/fX4HDmLFy+OF154IZ577rn9soaGhiguLo7y8vJO91dUVERDQ8MBt7dgwYK46aabejoNAAAAgGNOj47I2bhxY3zjG9+IBx98MAYMGHBYJjBv3rxoamrK3TZu3HhYtgsAAADwQdOjIqeuri62bNkSZ511VhQVFUVRUVGsWrUq7rrrrigqKoqKiopoa2uLbdu2dXpcY2NjVFZWHnCbJSUlUVpa2ukGAAAAwP569NGqiy66KNatW9fpvi9/+csxYcKEuP7662PMmDHRv3//WL58ecyaNSsiItavXx/19fVRVVV1+GYNAAAAcAzqUZEzZMiQOP300zvdN2jQoBg2bFju/ssvvzzmzp0bQ4cOjdLS0rj66qujqqoqzj333MM3aziGDR8+vMsxJ598cmo+atSo1LyoKP1HQ3t7e2r+5ptvpuYrVqxIzVeuXNmr7e/cuTM1BwAAyKoen+y4K7fffnv069cvZs2aFa2trVFdXR1333334X4aAAAAgGNOr4ucff/nfMCAAbFw4cJYuHBhbzcNAAAAwPv06GTHAAAAAOSPIgcAAAAgIxQ5AAAAABmhyAEAAADICEUOAAAAQEYc9suPA71TUFCQmldUVHS5jY997GOp+ejRo1Pz9vb21Hzr1q2p+auvvpqaP/XUU6n5unXrUvNt27al5gAAAB9UjsgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgI4ryPQE41hQUFKTm/fql96snnnhil89xwQUXpOZjx45NzVtaWlLz119/PTV/8cUXU/MXXnghNW9oaEjNAQAAjlWOyAEAAADICEUOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZIQiBwAAACAjivI9AaBndu3a1eWYzZs3p+bvvPNOar5z587U/Le//W1qvnbt2tR869atqXlbW1tqDgAAcKxyRA4AAABARihyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkhCIHAAAAICMUOQAAAAAZUZTvCQA98/bbb3c55oUXXujVNjZu3Jiar1+/PjXfunVrag4AAMChcUQOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZIQiBwAAACAjFDkAAAAAGVGU7wnAsSZJktS8o6MjNf/jH//Y5XOsWLEiNW9paUnNd+zY0ascAACAI8MROQAAAAAZocgBAAAAyAhFDgAAAEBGKHIAAAAAMkKRAwAAAJARihwAAACAjHD5cQAAAID3+YtvLd3vvjdvmZmHmexPkQN9TJIkqfm7777b5Ta6MwYAAIDs8dEqAAAAgIxQ5AAAAABkhI9WAQAAAB9IBzrXzYH0lfPfdIciBwBgHwsXLozvfe970dDQEFOmTIkf/OAHcc455+R7Wqn23VE90A5pXz5xIwAffH3536HuFj59gSIHAOB9fvKTn8TcuXPj3nvvjWnTpsUdd9wR1dXVsX79+hgxYkS+p5c5fXmnnd7z9wtE9J2fBVkqY3pDkQMA8D633XZbfO1rX4svf/nLERFx7733xtKlS+Nf/uVf4lvf+laeZ9d93d2Z7e7Od3e215d/ge/OEUtwMH3ll9TuONTv6b7yS3dfXdd8ONLr05uf/0f67+lYKWQOVZ8rcrq69DIAH3z+LSBf2traoq6uLubNm5e7r1+/fjF9+vSora094GNaW1ujtbU193VTU1NERDQ3Nx+xeXa07jxi24448Ny785xj5yw55O2f/u0nu/XYfb10U/Uhbau7c+3ucx7KHHqjO3PoyTwO52s60Np2d76H077z7c0cDvT+3/d9fKD16e7781Dfxwd6XHfmeqBxvfm+7M78ezPXfOjO/A/n99eBHM716c3376GO6+6/Jb35eXy0Hcn3595td2c/uCDpY3vLb731VowZMybf0wAgjzZu3BijR4/O9zQ4Bm3atClOPPHEePbZZ6Oqqip3/3XXXRerVq2KNWvW7PeYG2+8MW666aajOU0A4AOqO/vBfe6InFGjRsXGjRtjyJAhUVBQEM3NzTFmzJjYuHFjlJaW5nt6mWQNe8f69Y71651jbf2SJIn33nsvRo0ale+pQLfNmzcv5s6dm/u6o6Mj3nnnnRg2bFgUFBQc9uc71n4u9BXWPX+sfX5Y9/yx9vmTz7XvyX5wnyty+vXrd8D2qbS01Ju4l6xh71i/3rF+vXMsrV9ZWVm+p8AxbPjw4VFYWBiNjY2d7m9sbIzKysoDPqakpCRKSko63VdeXn6kpphzLP1c6Euse/5Y+/yw7vlj7fMnX2vf3f3gfkd4HgAAmVFcXBxTp06N5cuX5+7r6OiI5cuXd/qoFQBAvvS5I3IAAPJp7ty5MXv27Dj77LPjnHPOiTvuuCN27NiRu4oVAEA+9fkip6SkJL797W/vd8gy3WcNe8f69Y716x3rB0ffZz/72Xj77bdj/vz50dDQEGeeeWY88cQTUVFRke+pRYSfC/li3fPH2ueHdc8fa58/WVn7PnfVKgAAAAAOzDlyAAAAADJCkQMAAACQEYocAAAAgIxQ5AAAAABkRJ8vchYuXBh/8Rd/EQMGDIhp06bFb37zm3xPqU96+umn49Of/nSMGjUqCgoK4tFHH+2UJ0kS8+fPj5EjR8bAgQNj+vTp8dprr+Vnsn3QggUL4qMf/WgMGTIkRowYEZ/5zGdi/fr1nca0tLRETU1NDBs2LAYPHhyzZs2KxsbGPM24b7nnnnti8uTJUVpaGqWlpVFVVRW/+MUvcrm165lbbrklCgoK4pprrsndZw2BCPtFR8ONN94YBQUFnW4TJkzI5X4eHx6HY9/1nXfeicsuuyxKS0ujvLw8Lr/88ti+fftRfBXZ1NXaf+lLX9rve+BTn/pUpzHWvucO1+8b9fX1MXPmzDjuuONixIgR8c1vfjP27NlzNF9KpnRn3c8///z93vNXXHFFpzF9bd37dJHzk5/8JObOnRvf/va344UXXogpU6ZEdXV1bNmyJd9T63N27NgRU6ZMiYULFx4wv/XWW+Ouu+6Ke++9N9asWRODBg2K6urqaGlpOcoz7ZtWrVoVNTU1sXr16li2bFns3r07Lr744tixY0duzJw5c+Kxxx6LJUuWxKpVq2LTpk1x6aWX5nHWfcfo0aPjlltuibq6unj++efjwgsvjEsuuSRefvnliLB2PfHcc8/Fj370o5g8eXKn+60hYL/o6DnttNNi8+bNudszzzyTy/w8PjwOx77rZZddFi+//HIsW7YsHn/88Xj66afj61//+tF6CZnV1dpHRHzqU5/q9D3wb//2b51ya99zh+P3jfb29pg5c2a0tbXFs88+Gw888EAsWrQo5s+fn4+XlAndWfeIiK997Wud3vO33nprLuuT6570Yeecc05SU1OT+7q9vT0ZNWpUsmDBgjzOqu+LiOSRRx7Jfd3R0ZFUVlYm3/ve93L3bdu2LSkpKUn+7d/+LQ8z7Pu2bNmSRESyatWqJEn+vF79+/dPlixZkhvzH//xH0lEJLW1tfmaZp92/PHHJz/+8Y+tXQ+89957ySmnnJIsW7Ys+S//5b8k3/jGN5Ik8f4D/sx+0dHx7W9/O5kyZcoBMz+Pj4xD2Xd95ZVXkohInnvuudyYX/ziF0lBQUHyxz/+8ajNPev2XfskSZLZs2cnl1xyyUEfY+0Pj0P5fePnP/950q9fv6ShoSE35p577klKS0uT1tbWo/sCMmrfdU+SpNN+94H0xXXvs0fktLW1RV1dXUyfPj13X79+/WL69OlRW1ubx5llz4YNG6KhoaHTWpaVlcW0adOs5UE0NTVFRMTQoUMjIqKuri52797daQ0nTJgQY8eOtYb7aG9vj8WLF8eOHTuiqqrK2vVATU1NzJw5s9NaRXj/AfaLjrbXXnstRo0aFR/60Ifisssui/r6+ojw8/ho6c6+a21tbZSXl8fZZ5+dGzN9+vTo169frFmz5qjP+YNm5cqVMWLEiBg/fnxceeWVsXXr1lxm7Q+PQ/l9o7a2Ns4444yoqKjIjamuro7m5ubckfCk23fd93rwwQdj+PDhcfrpp8e8efNi586duawvrntRXp61G/70pz9Fe3t7p8WKiKioqIhXX301T7PKpoaGhoiIA67l3oz/p6OjI6655pr4+Mc/HqeffnpE/HkNi4uLo7y8vNNYa/j/rFu3LqqqqqKlpSUGDx4cjzzySEyaNCnWrl1r7bph8eLF8cILL8Rzzz23X+b9B9gvOnqmTZsWixYtivHjx8fmzZvjpptuik9+8pPx0ksv+Xl8lHRn37WhoSFGjBjRKS8qKoqhQ4f6u+ilT33qU3HppZfGuHHj4o033oj//t//e8yYMSNqa2ujsLDQ2h8Gh/r7RkNDwwG/L/ZmpDvQukdE/N3f/V2cdNJJMWrUqPjd734X119/faxfvz5++tOfRkTfXPc+W+RAvtTU1MRLL73U6fPwdG38+PGxdu3aaGpqin//93+P2bNnx6pVq/I9rUzYuHFjfOMb34hly5bFgAED8j0dgGPajBkzcn+ePHlyTJs2LU466aR4+OGHY+DAgXmcGRwdn/vc53J/PuOMM2Ly5Mnx4Q9/OFauXBkXXXRRHmf2weH3jfw42Lq///xOZ5xxRowcOTIuuuiieOONN+LDH/7w0Z5mt/TZj1YNHz48CgsL9ztLd2NjY1RWVuZpVtm0d72sZdeuuuqqePzxx+Opp56K0aNH5+6vrKyMtra22LZtW6fx1vD/KS4ujpNPPjmmTp0aCxYsiClTpsSdd95p7bqhrq4utmzZEmeddVYUFRVFUVFRrFq1Ku66664oKiqKiooKawjHOPtF+VNeXh6nnnpqvP766/5NO0q6s+9aWVm534m+9+zZE++8846/i8PsQx/6UAwfPjxef/31iLD2vdWb3zcqKysP+H2xN+PgDrbuBzJt2rSIiE7v+b627n22yCkuLo6pU6fG8uXLc/d1dHTE8uXLo6qqKo8zy55x48ZFZWVlp7Vsbm6ONWvWWMv/X5IkcdVVV8UjjzwSK1asiHHjxnXKp06dGv379++0huvXr4/6+npreBAdHR3R2tpq7brhoosuinXr1sXatWtzt7PPPjsuu+yy3J+tIRzb7Bflz/bt2+ONN96IkSNH+jftKOnOvmtVVVVs27Yt6urqcmNWrFgRHR0duV/CODzeeuut2Lp1a4wcOTIirP2hOhy/b1RVVcW6des6FWnLli2L0tLSmDRp0tF5IRnT1bofyNq1ayMiOr3n+9y65+UUy920ePHipKSkJFm0aFHyyiuvJF//+teT8vLyTmeL5s/ee++95MUXX0xefPHFJCKS2267LXnxxReTP/zhD0mSJMktt9ySlJeXJz/72c+S3/3ud8kll1ySjBs3Ltm1a1eeZ943XHnllUlZWVmycuXKZPPmzbnbzp07c2OuuOKKZOzYscmKFSuS559/PqmqqkqqqqryOOu+41vf+layatWqZMOGDcnvfve75Fvf+lZSUFCQ/PKXv0ySxNodin3Pnm8NAftFR8e1116brFy5MtmwYUPy61//Opk+fXoyfPjwZMuWLUmS+Hl8uByOfddPfepTyUc+8pFkzZo1yTPPPJOccsopyec///l8vaTMSFv79957L/n7v//7pLa2NtmwYUPyq1/9KjnrrLOSU045JWlpacltw9r33OH4fWPPnj3J6aefnlx88cXJ2rVrkyeeeCI54YQTknnz5uXjJWVCV+v++uuvJzfffHPy/PPPJxs2bEh+9rOfJR/60IeS8847L7eNvrjufbrISZIk+cEPfpCMHTs2KS4uTs4555xk9erV+Z5Sn/TUU08lEbHfbfbs2UmS/Pkyjv/wD/+QVFRUJCUlJclFF12UrF+/Pr+T7kMOtHYRkdx///25Mbt27Ur+23/7b8nxxx+fHHfcccnf/M3fJJs3b87fpPuQr3zlK8lJJ52UFBcXJyeccEJy0UUX5UqcJLF2h2LfIscaAkliv+ho+OxnP5uMHDkyKS4uTk488cTks5/9bPL666/ncj+PD4/Dse+6devW5POf/3wyePDgpLS0NPnyl7+cvPfee3l4NdmStvY7d+5MLr744uSEE05I+vfvn5x00knJ1772tf0KY2vfc4fr940333wzmTFjRjJw4MBk+PDhybXXXpvs3r37KL+a7Ohq3evr65PzzjsvGTp0aFJSUpKcfPLJyTe/+c2kqamp03b62roXJEmSHNljfgAAAAA4HPrsOXIAAAAA6EyRAwAAAJARihwAAACAjFDkAAAAAGSEIgcAAAAgIxQ5AAAAABmhyAEAAADICEUOAAAAQEYocgAAAAAyQpEDAAAAkBGKHAAAAICMUOQAAAAAZMT/B+UbjcB3u6O9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(15, 5))\n",
    "index = 5000\n",
    "\n",
    "print(y_train[index])\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[index],cmap=\"gray\");\n",
    "plt.subplot(122)\n",
    "_,_,_=plt.hist(X_train[index].ravel(),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fb95c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,848,586\n",
      "Trainable params: 133,898\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Cargar el modelo pre-entrenado  VGG16  (Excluir la capa de salida)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Congelar las capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear un nuevo modelo (clasificador)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))  # Asumiendo 10 clases\n",
    "\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# imprimir el resumen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a83f1033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 260s 431ms/step - loss: 0.7819 - accuracy: 0.8264\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 264s 441ms/step - loss: 0.2722 - accuracy: 0.9147\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 265s 441ms/step - loss: 0.2207 - accuracy: 0.9306\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 266s 444ms/step - loss: 0.1980 - accuracy: 0.9364\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 268s 446ms/step - loss: 0.1847 - accuracy: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a118e7d60>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "train_labels = to_categorical(y_train, num_classes=num_classes)\n",
    "test_labels = to_categorical(y_test, num_classes=num_classes)\n",
    "#entrenar el modelo\n",
    "model.fit(X_train, train_labels, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02f12ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 51s 162ms/step - loss: 0.1328 - accuracy: 0.9584\n",
      "Accuracy: 95.84\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, test_labels)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebef247",
   "metadata": {},
   "source": [
    "## Caso 2:\n",
    "utilizar un modelo ResNet previamente entrenado como extractor de características y agregar s capas densas personalizadas para la clasificación. Ejemplo usando TensorFlow y Keras:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Lcargar modelo ResNet50 \n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Congelar capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear nuevo modelo (clasificador)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))  # Asumiendo 10 clases\n",
    "\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Mostrar resumen\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "Explicación:\n",
    "1. Primero importamos las bibliotecas necesarias y cargamos el modelo ResNet50 previamente entrenado sin la capa superior (`include_top=False`).\n",
    "\n",
    "2. Congelamos las capas previamente entrenadas usando un bucle para evitar que se actualicen durante el entrenamiento.\n",
    "\n",
    ".....\n",
    "\n",
    "\n",
    "Ajuste la forma de entrada y la cantidad de clases de salida según su tarea específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d0f4a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 4s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               1048704   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,637,706\n",
      "Trainable params: 1,049,994\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Lcargar modelo ResNet50 \n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Congelar capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear nuevo modelo (clasificador)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))  # Asumiendo 10 clases\n",
    "\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Mostrar resumen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76358f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 187s 304ms/step - loss: 0.4674 - accuracy: 0.8543\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 179s 298ms/step - loss: 0.2443 - accuracy: 0.9233\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 182s 304ms/step - loss: 0.2101 - accuracy: 0.9339\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 182s 304ms/step - loss: 0.1816 - accuracy: 0.9425\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 188s 314ms/step - loss: 0.1646 - accuracy: 0.9466\n",
      "313/313 [==============================] - 46s 142ms/step - loss: 0.0824 - accuracy: 0.9757\n",
      "Accuracy: 97.57\n"
     ]
    }
   ],
   "source": [
    "#entrenar el modelo\n",
    "model.fit(X_train, train_labels, epochs=5, batch_size=100)\n",
    "_, accuracy = model.evaluate(X_test, test_labels)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1cd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a96abab",
   "metadata": {},
   "source": [
    "## Caso 3:\n",
    "\n",
    "Utilizar un modelo MobileNet previamente entrenado como extractor de características y agregar capas densas personalizadas para la clasificación. Ejemplo usando TensorFlow y Keras:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Cargar MobileNetV2 \n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Congelar capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear clasificador\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # Asumir 10 clases\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# mostrar resultado\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "Ajuste la forma de entrada y la cantidad de clases de salida según su tarea específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84210501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 2, 2, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,423,242\n",
      "Trainable params: 165,258\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Cargar MobileNetV2 \n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Congelar capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear clasificador\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # Asumir 10 clases\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# mostrar resultado\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55db5417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 38s 60ms/step - loss: 0.4601 - accuracy: 0.8508\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.2910 - accuracy: 0.9043\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 37s 62ms/step - loss: 0.2464 - accuracy: 0.9182\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 36s 59ms/step - loss: 0.2192 - accuracy: 0.9271\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.1994 - accuracy: 0.9331\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2671 - accuracy: 0.9156\n",
      "Accuracy: 91.56\n"
     ]
    }
   ],
   "source": [
    "#entrenar el modelo\n",
    "model.fit(X_train, train_labels, epochs=5, batch_size=100)\n",
    "_, accuracy = model.evaluate(X_test, test_labels)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1f79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
