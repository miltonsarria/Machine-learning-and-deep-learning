{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ccf442",
   "metadata": {},
   "source": [
    "# Data Augmentation - Generación de datos de forma artificial\n",
    "\n",
    "El aumento de datos es una técnica para aumentar la diversidad de su conjunto de datos de entrenamiento aplicando varias transformaciones a las imágenes existentes. Esto ayuda a que el modelo se generalice mejor. Ejemplo que utiliza TensorFlow y Keras para el aumento de datos en la clasificación de imágenes:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definir los parametros\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Cargar y procesar sus datos (Asumiendo que los tiene en un directorio)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'path_to_train_directory',\n",
    "    target_size=(224, 224),  # Ajustar\n",
    "    batch_size=32,           # Ajustar\n",
    "    class_mode='categorical' # Depende de la tarea (binary , categorical classification)\n",
    ")\n",
    "\n",
    "# Crear y compilar su modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "    # ... agregar las capas necesarias\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# entrenar su modelo\n",
    "model.fit(train_generator, epochs=5)\n",
    "```\n",
    "Explicación:\n",
    "\n",
    "1. Importamos las bibliotecas necesarias, incluidas `tf` para TensorFlow e `ImageDataGenerator` para aumento de datos.\n",
    "\n",
    "2. Definimos `ImageDataGenerator` con varios parámetros de aumento como rotación, desplazamientos, corte, zoom, giro horizontal y modo de relleno.\n",
    "\n",
    "3. Suponiendo que tiene un conjunto de datos organizado en una estructura de directorios (un subdirectorio por clase), puede usar `flow_from_directory` para cargar y preprocesar los datos. Ajuste `target_size` y `batch_size` según sus necesidades.\n",
    "\n",
    "4. Crea un modelo de red neuronal. Reemplace el comentario con las capas de su modelo real.\n",
    "\n",
    "5. Compile el modelo con un optimizador, una función de pérdida (entropía cruzada categórica en este ejemplo) y las métricas deseadas.\n",
    "\n",
    "6. Entrene el modelo utilizando los datos aumentados del generador.\n",
    "\n",
    "Recuerde reemplazar `'path_to_train_directory'` con la ruta real a su directorio de datos de entrenamiento. Además, personalice los parámetros de aumento para que se adapten mejor a su conjunto de datos específico y a su tarea de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2a0ca",
   "metadata": {},
   "source": [
    "# Ejemplo\n",
    "\n",
    "Usar la base de datos `hymenoptera` :\n",
    "\n",
    "1. Construir un modelo de red convolucional \n",
    "\n",
    "2. Usar la base de datos para realizar el proceso de entrenamiento \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3304c9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 186624)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                11944000  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,963,457\n",
      "Trainable params: 11,963,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define el modelo CNN\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa convolucional\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Segunda capa convolucional\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten Layer : permite concatenar las caracteristicas en un vector unidimensional (aplanar)\n",
    "#sirve para preparar los datos de entrada a una red completamente conectada (FC - fully connected)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(layers.Dense(1, activation='softmax'))  # En este caso se tienen 10 clases \n",
    "\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# mostar el resumen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49eb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57eb040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 images belonging to 2 classes.\n",
      "Found 153 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definir los parametros\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Cargar y procesar sus datos (Asumiendo que los tiene en un directorio)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'C:/Users/sarria/OneDrive/Documents/2023B/DL/Lab2/hymenoptera/train',\n",
    "    target_size=(224, 224),  # Ajustar\n",
    "    batch_size=32,           # Ajustar\n",
    "    class_mode='binary' # Depende de la tarea (binary , categorical classification)\n",
    ")\n",
    "\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1 / 255.0,)\n",
    "test_generator = datagen_test.flow_from_directory(\n",
    "    'C:/Users/sarria/OneDrive/Documents/2023B/DL/Lab2/hymenoptera/val',\n",
    "    target_size=(224, 224),  # Ajustar\n",
    "    batch_size=32,           # Ajustar\n",
    "    class_mode='binary' # Depende de la tarea (binary , categorical classification)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4659a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ants', 'bees'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9577c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.6824 - accuracy: 0.4959\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - 6s 686ms/step - loss: 0.6817 - accuracy: 0.4959\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.6771 - accuracy: 0.4959\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - 7s 805ms/step - loss: 0.6595 - accuracy: 0.4959\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - 7s 852ms/step - loss: 0.6532 - accuracy: 0.4959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231f07d0430>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenar su modelo\n",
    "model.fit(train_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce02f181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 211ms/step - loss: 0.6757 - accuracy: 0.5425\n",
      "Accuracy: 54.25\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(x=test_generator)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd9c1b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "5/5 [==============================] - 1s 214ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.46      1.00      0.63        70\n",
      "        bees       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.46       153\n",
      "   macro avg       0.23      0.50      0.31       153\n",
      "weighted avg       0.21      0.46      0.29       153\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarria\\anaconda3\\envs\\ann\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sarria\\anaconda3\\envs\\ann\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sarria\\anaconda3\\envs\\ann\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"[INFO] evaluating network...\")\n",
    "test_generator.reset()\n",
    "predIdxs = model.predict(x=test_generator)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "print(classification_report(test_generator.classes, predIdxs,\n",
    "target_names=test_generator.class_indices.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
