{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3294a7",
   "metadata": {},
   "source": [
    "# CNN - redes neuronales convolucionales\n",
    "\n",
    "Vamos a implementar diferentes modelos de redes convolucionales y realizar el ejercicio de probar su funcionamiento con la base de datos MNIST\n",
    "\n",
    "### Caso 1:\n",
    "\n",
    "Ejemplo de una red neuronal convolucional (CNN) de tres capas que utiliza TensorFlow para clasificar imágenes. Este ejemplo supone una arquitectura simple con dos capas convolucionales seguidas de agrupación máxima y una capa completamente conectada para la clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61e7fc",
   "metadata": {},
   "source": [
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define el modelo CNN\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa convolucional\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Segunda capa convolucional\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten Layer : permite concatenar las caracteristicas en un vector unidimensional (aplanar)\n",
    "#sirve para preparar los datos de entrada a una red completamente conectada (FC - fully connected)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(layers.Dense(10, activation='softmax'))  # En este caso se tienen 10 clases \n",
    "\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# mostar el resumen\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "**Explicación:**\n",
    "\n",
    "1. **Capas convolucionales**: las dos primeras capas son capas convolucionales. Están diseñados para aprender características a partir de los datos de entrada. Las capas `Conv2D` aplican un conjunto de filtros a la entrada y cada filtro aprende una característica diferente.\n",
    "\n",
    "2. **Capas pooling o agrupacion MaxPooling**: después de cada capa convolucional, hay una capa de agrupación  (`MaxPooling2D`). Esta capa reduce las dimensiones espaciales (ancho y alto) de los datos, lo que ayuda a reducir el cálculo y evita el sobreajuste.\n",
    "\n",
    "3. **Flatten Layer**: esta capa se utiliza para convertir los datos multidimensionales en una matriz unidimensional. Esto es necesario antes de pasar los datos a capas completamente conectadas.\n",
    "\n",
    "4. **Capas completamente conectadas - Fully connected**: los datos aplanados pasan a través de una o más capas completamente conectadas, que realizan la tarea de clasificación.\n",
    "\n",
    "5. **Capa de salida**: la capa final utiliza la función de activación softmax para generar probabilidades para cada clase.\n",
    "\n",
    "6. **Compilación**: el modelo se compila con un optimizador, una función de pérdida y la métrica deseada para su evaluación.\n",
    "\n",
    "7. **Resumen del modelo**: Esto imprime un resumen de la arquitectura del modelo.\n",
    "\n",
    "Recuerde ajustar los parámetros (por ejemplo, forma de entrada, número de clases, tamaños de filtro, etc.) de acuerdo con su conjunto de datos específico y su tarea de clasificación.\n",
    "\n",
    "Además, necesitará un conjunto de datos para entrenar y evaluar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive',force_remount=True)\n",
    "#root_dir = '/content/gdrive/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ca5d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] datos cargados y redimensionados a la forma: num imagenes x filas x columnas x canales\n",
      " \n",
      "Etiquetas o clases: \n",
      " [0 1 2 3 4 5 6 7 8 9] \n",
      "Datos por clase \n",
      " [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot       as plt\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "root_dir = ''\n",
    "\n",
    "X_train, y_train = loadlocal_mnist(\n",
    "        images_path=root_dir+'MNIST/train-images-idx3-ubyte', \n",
    "        labels_path=root_dir+'MNIST/train-labels-idx1-ubyte')\n",
    "\n",
    "X_test, y_test = loadlocal_mnist(\n",
    "        images_path=root_dir+'MNIST/t10k-images-idx3-ubyte', \n",
    "        labels_path=root_dir+'MNIST/t10k-labels-idx1-ubyte')\n",
    "\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] datos cargados y redimensionados a la forma: num imagenes x filas x columnas x canales\")\n",
    "labels,count_class = np.unique(y_train,return_counts=True)\n",
    "print(' \\nEtiquetas o clases: \\n %s \\nDatos por clase \\n %s' % (labels,count_class))\n",
    "num_classes = labels.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5772bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(15, 5))\n",
    "index = 5000\n",
    "\n",
    "print(y_train[index])\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[index],cmap=\"gray\");\n",
    "plt.subplot(122)\n",
    "_,_,_=plt.hist(X_train[index].ravel(),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e755bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,930\n",
      "Trainable params: 121,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define el modelo CNN\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa convolucional\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Segunda capa convolucional\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten Layer : permite concatenar las caracteristicas en un vector unidimensional (aplanar)\n",
    "#sirve para preparar los datos de entrada a una red completamente conectada (FC - fully connected)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(layers.Dense(10, activation='softmax'))  # En este caso se tienen 10 clases \n",
    "\n",
    "# Compile el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# mostar el resumen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6903d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 12s 19ms/step - loss: 0.7552 - accuracy: 0.9098\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0821 - accuracy: 0.9757\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0552 - accuracy: 0.9829\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0410 - accuracy: 0.9870\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0332 - accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28ff6a36e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "train_labels = to_categorical(y_train, num_classes=num_classes)\n",
    "test_labels = to_categorical(y_test, num_classes=num_classes)\n",
    "#entrenar el modelo\n",
    "model.fit(X_train, train_labels, epochs=5, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "995d4ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0637 - accuracy: 0.9833\n",
      "Accuracy: 98.33\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, test_labels)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b86d8",
   "metadata": {},
   "source": [
    "### Caso 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1d3b3",
   "metadata": {},
   "source": [
    "Ejemplo de una red neuronal convolucional residual (ResNet) de tres capas que utiliza TensorFlow para clasificar imágenes. ResNet utiliza conexiones de salto (o atajos) para abordar el problema del gradiente que desaparece y mejorar el entrenamiento de redes profundas.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    # Atajo o Shortcut: es la entrada al bloque, se usa para sumarlo al final con\n",
    "    #el resultado de pasar esta misma entrada por las capas convolucionales\n",
    "    shortcut = x\n",
    "    \n",
    "    # Primer capa convolucional\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Segunda capa convolucional\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Sumar el atajo con la salida de las capas convolucionales , generar la salida del bloque\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Definir el modelo ResNet\n",
    "def build_resnet():\n",
    "    input_layer = layers.Input(shape=(64, 64, 3))\n",
    "    \n",
    "    # Capa convolucional inicial\n",
    "    x = layers.Conv2D(32, 3, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Agregar los bloques residuales, en este caso se itera por 3 ciclos, para pasar x \n",
    "    # por 3 bloques identicos\n",
    "    for _ in range(3):  # Three residual blocks\n",
    "        x = residual_block(x, 32)\n",
    "    \n",
    "    # Pooling promedi\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Fully Connected \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    # Output Layer - capa de salida\n",
    "    output_layer = layers.Dense(10, activation='softmax')(x)  # Suponiendo que tenemos 10 clases\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = build_resnet()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# imprimir resumen\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "**Explicación**:\n",
    "\n",
    "1. **Función de bloque residual**: `residual_block` define un único bloque residual. Consta de dos capas convolucionales con normalización por lotes y activación ReLU, y una conexión directa. La salida del bloque es la suma de elementos del atajo y el resultado de las dos convoluciones.\n",
    "\n",
    "`BatchNormalization()` es una técnica utilizada en redes neuronales para normalizar las activaciones de una capa, lo que contribuye a una mayor estabilidad y velocidad de entrenamiento.\n",
    "\n",
    "La normalización por lotes (Batch Normalization) se aplica en una capa de una red neuronal después de la operación de convolución o la operación lineal. Consiste en dos pasos principales:\n",
    "\n",
    "    a. Normalización: Se calcula la media y la desviación estándar de las activaciones en el lote de entrenamiento actual.\n",
    "\n",
    "    b. Escala y Desplazamiento: Las activaciones se normalizan restando la media y dividiendo por la desviación estándar. Luego, se escalan y se desplazan utilizando dos parámetros aprendibles (gamma y beta). Esto permite que la red aprenda la mejor representación de los datos para el problema en cuestión.\n",
    "\n",
    "La normalización por lotes ayuda a combatir el problema de la desvanecimiento/explotación del gradiente en redes profundas.\n",
    "\n",
    "\n",
    "2. **Bloques residuales en el modelo**: En la función `build_resnet`, comenzamos con una capa convolucional inicial, seguida de tres bloques residuales.\n",
    "\n",
    "3. **Agrupación promedio global - GlobalAveragePooling**: después de los bloques residuales, utilizamos la agrupación promedio global para convertir las dimensiones espaciales en un vector unidimensional.\n",
    "\n",
    "4. **Capa completamente conectada - Fully connected**: los datos aplanados pasan a través de una capa completamente conectada.\n",
    "\n",
    "5. **Capa de salida - Output Layer**: la capa final utiliza la función de activación softmax para generar probabilidades para cada clase.\n",
    "\n",
    "6. **Compilación**: el modelo se compila con un optimizador, una función de pérdida y la métrica deseada para su evaluación.\n",
    "\n",
    "7. **Resumen del modelo**: Esto imprime un resumen de la arquitectura del modelo.\n",
    "\n",
    "Recuerde ajustar los parámetros (por ejemplo, forma de entrada, número de clases, tamaños de filtro, etc.) de acuerdo con su conjunto de datos específico y su tarea de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05acf0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 32)  128         ['conv2d_2[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 28, 28, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 32)   9248        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 28, 28, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 28, 28, 32)   9248        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 28, 28, 32)   0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  're_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 28, 28, 32)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 28, 28, 32)   9248        ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 28, 28, 32)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 28, 28, 32)   9248        ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 28, 28, 32)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  're_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 28, 28, 32)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 28, 28, 32)   9248        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 28, 28, 32)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 28, 28, 32)   9248        ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 28, 28, 32)   0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  're_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 28, 28, 32)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 32)          0           ['re_lu_6[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           2112        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           650         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 59,466\n",
      "Trainable params: 59,018\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    # Atajo o Shortcut: es la entrada al bloque, se usa para sumarlo al final con\n",
    "    #el resultado de pasar esta misma entrada por las capas convolucionales\n",
    "    shortcut = x\n",
    "    \n",
    "    # Primer capa convolucional\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Segunda capa convolucional\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Sumar el atajo con la salida de las capas convolucionales , generar la salida del bloque\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Definir el modelo ResNet\n",
    "def build_resnet():\n",
    "    input_layer = layers.Input(shape=(28, 28, 1))\n",
    "    \n",
    "    # Capa convolucional inicial\n",
    "    x = layers.Conv2D(32, 3, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Agregar los bloques residuales, en este caso se itera por 3 ciclos, para pasar x \n",
    "    # por 3 bloques identicos\n",
    "    for _ in range(3):  # Three residual blocks\n",
    "        x = residual_block(x, 32)\n",
    "    \n",
    "    # Pooling promedi\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Fully Connected \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    # Output Layer - capa de salida\n",
    "    output_layer = layers.Dense(10, activation='softmax')(x)  # Suponiendo que tenemos 10 clases\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = build_resnet()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# imprimir resumen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9dc7c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 96s 159ms/step - loss: 0.4134 - accuracy: 0.8896\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 96s 161ms/step - loss: 0.0836 - accuracy: 0.9763\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 97s 162ms/step - loss: 0.0608 - accuracy: 0.9819\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 97s 162ms/step - loss: 0.0482 - accuracy: 0.9860\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 98s 164ms/step - loss: 0.0448 - accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28ff7f911c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "train_labels = to_categorical(y_train, num_classes=num_classes)\n",
    "test_labels = to_categorical(y_test, num_classes=num_classes)\n",
    "#entrenar el modelo\n",
    "model.fit(X_train, train_labels, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c73ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 1.0715 - accuracy: 0.6806\n",
      "Accuracy: 68.06\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, test_labels)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec37e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89db491a",
   "metadata": {},
   "source": [
    "### Caso 3:\n",
    "\n",
    "La arquitectura VGG es conocida por sus profundas capas convolucionales. A continuación se muestra un ejemplo de una red neuronal convolucional (CNN) de tres capas que utiliza la arquitectura VGG con TensorFlow:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_vgg(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Boque 1\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Boque 2\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Boque 3\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Crear el modelo VGG\n",
    "input_shape = (224, 224, 3)  # Ajustar segun necesidades\n",
    "num_classes = 10  # Asumir 10 clases\n",
    "\n",
    "model = build_vgg(input_shape, num_classes)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Mostrar el resumen\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "**Explicación**\n",
    "1. **Bloque 1**: Contiene dos capas convolucionales con 64 filtros cada una, seguidas de una agrupación máxima.\n",
    "\n",
    "2. **Bloque 2**: Contiene dos capas convolucionales con 128 filtros cada una, seguidas de una agrupación máxima.\n",
    "\n",
    "3. **Bloque 3**: Contiene tres capas convolucionales con 256 filtros cada una, seguidas de una agrupación máxima.\n",
    "\n",
    "4. **Capas aplanadas y completamente conectadas - Flatten and Fully Connected Layers**: después de los bloques convolucionales, los datos se aplanan y pasan a través de dos capas completamente conectadas con 4096 unidades cada una.\n",
    "\n",
    "5. **Capa de salida - Output Layer**: la capa final utiliza la función de activación softmax para generar probabilidades para cada clase.\n",
    "\n",
    "Recuerde ajustar `input_shape` de acuerdo con las dimensiones de sus imágenes y configurar `num_classes` para que coincida con el número de clases en su tarea de clasificación. Además, prepare su conjunto de datos para entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e73f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              9441280   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,997,898\n",
      "Trainable params: 27,997,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_vgg(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Boque 1\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Boque 2\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Boque 3\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Crear el modelo VGG\n",
    "input_shape = (28, 28, 1)  # Ajustar segun necesidades\n",
    "num_classes = 10  # Asumir 10 clases\n",
    "\n",
    "model = build_vgg(input_shape, num_classes)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Mostrar el resumen\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69f71ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 264s 438ms/step - loss: 0.3305 - accuracy: 0.9348\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 250s 416ms/step - loss: 0.0549 - accuracy: 0.9837\n",
      "Epoch 3/10\n",
      "481/600 [=======================>......] - ETA: 49s - loss: 0.0445 - accuracy: 0.9866"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m to_categorical(y_test, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#entrenar el modelo\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ann\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#one hot encoding\n",
    "train_labels = to_categorical(y_train, num_classes=num_classes)\n",
    "test_labels = to_categorical(y_test, num_classes=num_classes)\n",
    "#entrenar el modelo\n",
    "model.fit(X_train, train_labels, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "821d74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 15s 48ms/step - loss: 0.0847 - accuracy: 0.9798\n",
      "Accuracy: 97.98\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, test_labels)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c102db",
   "metadata": {},
   "source": [
    "### Caso 4:\n",
    "Un ejemplo de una red neuronal convolucional (CNN) de tres capas que utiliza la arquitectura VGG con convoluciones separables en TensorFlow:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_vgg_separable(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Bloque 1 con Separable Convolutions\n",
    "    model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Bloque 2 con Separable Convolutions\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Bloque 3 con Separable Convolutions\n",
    "    model.add(layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Crear el modelo VGG\n",
    "input_shape = (224, 224, 3)  # ajustar de acuerdo a necesidades\n",
    "num_classes = 10  # Assumir 10 clases\n",
    "\n",
    "model = build_vgg_separable(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Imprimir el resumen\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "En este ejemplo, se utilizan las capas `SeparableConv2D` en lugar de las capas convolucionales normales. Las convoluciones separables son computacionalmente más eficientes que las convoluciones tradicionales, ya que factorizan la operación en una convolución profunda y una convolución puntual. Esto puede conducir a una reducción en la cantidad de parámetros y el costo computacional.\n",
    "\n",
    "Recuerde ajustar `input_shape` de acuerdo con las dimensiones de sus imágenes y configurar `num_classes` para que coincida con el número de clases en su tarea de clasificación. Además, prepare su conjunto de datos para entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "871ac682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " separable_conv2d_7 (Separab  (None, 28, 28, 64)       137       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d_8 (Separab  (None, 28, 28, 64)       4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " separable_conv2d_9 (Separab  (None, 14, 14, 128)      8896      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d_10 (Separa  (None, 14, 14, 128)      17664     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " separable_conv2d_11 (Separa  (None, 7, 7, 256)        34176     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " separable_conv2d_12 (Separa  (None, 7, 7, 256)        68096     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " separable_conv2d_13 (Separa  (None, 7, 7, 256)        68096     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 3, 3, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 4096)              9441280   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,465,363\n",
      "Trainable params: 26,465,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_vgg_separable(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Bloque 1 con Separable Convolutions\n",
    "    model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Bloque 2 con Separable Convolutions\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Bloque 3 con Separable Convolutions\n",
    "    model.add(layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Crear el modelo VGG\n",
    "input_shape = (28, 28, 1)  # ajustar de acuerdo a necesidades\n",
    "num_classes = 10  # Assumir 10 clases\n",
    "\n",
    "model = build_vgg_separable(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Imprimir el resumen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d2fdb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 287s 476ms/step - loss: 2.3017 - accuracy: 0.1113\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 296s 493ms/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 311s 518ms/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 302s 503ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 310s 516ms/step - loss: 2.3013 - accuracy: 0.1124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2071fe417c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "train_labels = to_categorical(y_train, num_classes=num_classes)\n",
    "test_labels = to_categorical(y_test, num_classes=num_classes)\n",
    "#entrenar el modelo\n",
    "model.fit(X_train, train_labels, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dc21cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 28ms/step - loss: 2.3011 - accuracy: 0.1135\n",
      "Accuracy: 11.35\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, test_labels)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e850ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
