{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e13ccd",
   "metadata": {},
   "source": [
    "## Generating text with an RNN\n",
    "\n",
    "This tutorial demonstrates how to generate text using a character-based RNN. (Given a sequence of characters, train a model to predict the next character in the sequence.) Longer text sequences can be generated by calling the model repeatedly.\n",
    "\n",
    "While some of the sentences are grammatically correct, most are nonsense. The model has not learned the meaning of the words, but consider:\n",
    "\n",
    "      1. The model is based on characters. When the training began, the model did not know how to spell a word in English, or even that the words were a unit of text.\n",
    "\n",
    "      2. The structure of the output resembles a play: text blocks typically begin with a speaker's name, in all capital letters, similar to the data set.\n",
    "\n",
    "     3. As demonstrated below, the model is trained on small batches of text (100 characters each) and can still generate a longer text stream with a consistent structure.\n",
    "    \n",
    "For this example the following book will be used:\n",
    "\n",
    "Alice's Adventures in Wonderland by Project Gutenberg, by Lewis Carroll\n",
    "\n",
    "This e-book is for the use of anyone anywhere at no cost and with almost no restrictions of any kind. You may copy, gift, or reuse it under the terms of the included Project Gutenberg License\n",
    "with this ebook or online at www.gutenberg.org\n",
    "\n",
    "Title: Alice's Adventures in Wonderland\n",
    "\n",
    "Author: Lewis Carroll\n",
    "\n",
    " \n",
    "**Task to do**: Given a character, or a sequence of characters, what is the most likely next character? This is the task for which you are training the model. The input to the model will be a sequence of characters, and you train the model to predict the output: the next character at each time step.\n",
    "\n",
    "Since RNNs maintain an internal state that depends on the items seen previously, given all the characters computed so far, what is the next character?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842dd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from __future__ import print_function\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0673383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Extracting text from input...\n",
      "[INFO] Done!!\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = \"texto/wonderland.txt\"\n",
    "# extract the input as a stream of characters\n",
    "print(\"[INFO]Extracting text from input...\")\n",
    "fin = open(INPUT_FILE, 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)\n",
    "print(\"[INFO] Done!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafbf4c",
   "metadata": {},
   "source": [
    "Here chars is the number of features in our \"vocabulary\" of characters. Create entries and responses (tags) from text. We do this by stepping through the $STEP$ text character at a time, and extracting a sequence of size $SEQLEN$ and the next output character. For example, assuming an input text \"The sky was falling\", we would get the following sequence of input_chars and label_chars (only the first 5)\n",
    "\n",
    "    The sky wa -> s\n",
    "    he sky was ->  \n",
    "    e sky was  -> f\n",
    "    sky was f -> a\n",
    "    sky was fa -> l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6270837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creaetiquetas y frases cortas de entrada...\n",
      "[INFO] Hecho!! \n",
      "Total simbolos: 55\n",
      "Total secuencias: 158773\n"
     ]
    }
   ],
   "source": [
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(\"[INFO] Creaetiquetas y frases cortas de entrada...\")\n",
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "    \n",
    "print(f\"[INFO] Hecho!! \\nTotal simbolos: {nb_chars}\\nTotal secuencias: {len(input_chars)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2126c7",
   "metadata": {},
   "source": [
    "vectorize the input and output characters (label). Each row of the input is represented by seqlen characters, each character represented as a 1-hot encoding of size len(chars). There are len(input_chars) rows, so the dimensions of (X) is: (len(input_chars), seqlen, nb_chars). Each output row is a single character, also represented as a dense encoding of size len(chars). Therefore, the dimensions of (y) are (len(input_chars),nb_chars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf5ae24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Vectorizing input and label text...\n",
      "[INFO] Done!!\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Vectorizing input and label text...\")\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "print(\"[INFO] Done!!\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf356f1",
   "metadata": {},
   "source": [
    "Build the model. We use a single RNN with a fully connected layer to compute the most likely predicted output character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67095a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_chars),\n",
    "                    unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a6968",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3297d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "1241/1241 [==============================] - 14s 8ms/step - loss: 2.3377\n",
      "Generating from seed:  the water\n",
      " the water alice said the the the the the the the the the the the the the the the the the the the the the the \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 2.0466\n",
      "Generating from seed:  be angry \n",
      " be angry hat ing the the said the the said the the said the the said the the said the the said the the said t\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.9443\n",
      "Generating from seed: ine feet h\n",
      "ine feet her all the said the king the hard the har her alice the har her alice the har her alice the har her \n",
      "==================================================\n",
      "Iteration #: 3\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.8677\n",
      "Generating from seed: hind to ex\n",
      "hind to exp of the she had she was the said the doon the dorme fing the reall sel was the said the doon the do\n",
      "==================================================\n",
      "Iteration #: 4\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.8038\n",
      "Generating from seed: right hold\n",
      "right holder and the hat it was so the said the cateres and the parted the parted the parted the parted the pa\n",
      "==================================================\n",
      "Iteration #: 5\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.7513\n",
      "Generating from seed:  the defec\n",
      " the defection and the gryphon and all the dore the gryphon and all the dore the gryphon and all the dore the \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.7063\n",
      "Generating from seed: . and how \n",
      ". and how it what she was goong the dorme say all the dorme say all the dorme say all the dorme say all the do\n",
      "==================================================\n",
      "Iteration #: 7\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.6667\n",
      "Generating from seed: the table \n",
      "the table said the dormouse of the courte and said the dormouse of the courte and said the dormouse of the cou\n",
      "==================================================\n",
      "Iteration #: 8\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.6325\n",
      "Generating from seed:  a timid v\n",
      " a timid very surped the rabbit was she had so the was she had so the was she had so the was she had so the wa\n",
      "==================================================\n",
      "Iteration #: 9\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.6037\n",
      "Generating from seed: atch out o\n",
      "atch out of the some of the could the mound the donter the her said the cat her hand the mound the donter the \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.5784\n",
      "Generating from seed: lf in a lo\n",
      "lf in a long to the poor and said the mock turtle said the mock turtle said the mock turtle said the mock turt\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.5554\n",
      "Generating from seed:  was quite\n",
      " was quite forgond in a little she was a little she was a little she was a little she was a little she was a l\n",
      "==================================================\n",
      "Iteration #: 12\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.5358\n",
      "Generating from seed: hile the p\n",
      "hile the project gutenberg-tm erection of the said to herself and the mock turtle so the formouse was the was \n",
      "==================================================\n",
      "Iteration #: 13\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.5193\n",
      "Generating from seed: sea! but t\n",
      "sea! but the tone, and the poor and her hears and reading the caterpillar. i she to get in the court in a litt\n",
      "==================================================\n",
      "Iteration #: 14\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.5031\n",
      "Generating from seed: ught herse\n",
      "ught herself in a little good the mock turtle so the gomant the works with the works with the works with the w\n",
      "==================================================\n",
      "Iteration #: 15\n",
      "1241/1241 [==============================] - 12s 9ms/step - loss: 1.4890\n",
      "Generating from seed: st the doo\n",
      "st the door and said the king the caterpillar was of the could she had not go said alice said the king the cat\n",
      "==================================================\n",
      "Iteration #: 16\n",
      "1241/1241 [==============================] - 12s 10ms/step - loss: 1.4765\n",
      "Generating from seed: if an indi\n",
      "if an inding as she could she was a said to herself the project gutenberg-tm electronic work in a voice of the\n",
      "==================================================\n",
      "Iteration #: 17\n",
      "1241/1241 [==============================] - 12s 9ms/step - loss: 1.4642\n",
      "Generating from seed:  caterpill\n",
      " caterpillar of the whought alice. alice little with a little with a little with a little with a little with a\n",
      "==================================================\n",
      "Iteration #: 18\n",
      "1241/1241 [==============================] - 12s 10ms/step - loss: 1.4536\n",
      "Generating from seed:  said the \n",
      " said the king, and the mock turtle to see in the works in the works in the works in the works in the works in\n",
      "==================================================\n",
      "Iteration #: 19\n",
      "1241/1241 [==============================] - 12s 10ms/step - loss: 1.4441\n",
      "Generating from seed: rranty or \n",
      "rranty or a great had and distribution of the court in a little to see it was the dormouse to see it was the d\n",
      "==================================================\n",
      "Iteration #: 20\n",
      "1241/1241 [==============================] - 12s 10ms/step - loss: 1.4344\n",
      "Generating from seed:  the fourt\n",
      " the fourter head of the project gutenberg-tm electronic work in a long to the project gutenberg-tm electronic\n",
      "==================================================\n",
      "Iteration #: 21\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.4254\n",
      "Generating from seed:  she fanci\n",
      " she fancied on the same of the same of the same of the same of the same of the same of the same of the same o\n",
      "==================================================\n",
      "Iteration #: 22\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.4177\n",
      "Generating from seed: e-tree, sh\n",
      "e-tree, she was she had got to be a looked an the mouse of the mouse of the mouse of the mouse of the mouse of\n",
      "==================================================\n",
      "Iteration #: 23\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.4112\n",
      "Generating from seed: you were a\n",
      "you were alice said alice. i dont know and the mouse one, the mock turtle in a more of the other face on the e\n",
      "==================================================\n",
      "Iteration #: 24\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.4039\n",
      "Generating from seed: in, but it\n",
      "in, but it was a large time to be a little to be to the court in the mouse were the souph alice went on and al\n"
     ]
    }
   ],
   "source": [
    "# We train the model in batches and test output generated at each step\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100 chars\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96cb3e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2a5de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
