{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_small_VGG_hand.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vesyWdiSSycg"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FespAevRTgSF"
      },
      "source": [
        "\n",
        "#define the paths\n",
        "root_dir = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
        "data_dir = root_dir + 'data/'\n",
        "model_dir = root_dir + 'models/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDsxP7atS07E"
      },
      "source": [
        "## Create a class model from keras\n",
        "\n",
        "\n",
        "```\n",
        "class SmallerVGGNet:\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTBnfuaheonO"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import backend as K\n",
        "    \n",
        "#########\n",
        "class SmallerVGGNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # initialize the model along with the input shape to be\n",
        "        # \"channels last\" and the channels dimension itself\n",
        "        model = Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "        # if we are using \"channels first\", update the input shape\n",
        "        # and channels dimension\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "            chanDim = 1\n",
        "        # CONV => RELU => POOL\n",
        "        model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # first (and only) set of FC => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "        # softmax classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "        # return the constructed network architecture\n",
        "        return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22hwmW2FfViH"
      },
      "source": [
        "# import the necessary packages\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnMBViRbeTg8"
      },
      "source": [
        "#########\n",
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# batch size, and image dimensions\n",
        "#\n",
        "#model_dir = 'models/'\n",
        "#data_dir = 'data/'\n",
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 50\n",
        "# initialize the data and labels\n",
        "data = []\n",
        "labels = []\n",
        "#load images\n",
        "print(\"[INFO] loading images...\")\n",
        "data_file = ['g1.p', 'g2.p', 'nada.p']\n",
        "clases   = ['uno','dos','nada']\n",
        "size = (224, 224,3)\n",
        "# loop over the files\n",
        "for fh,label in zip(data_file,clases):\n",
        "    fh =  data_dir + fh\n",
        "    matrix = pickle.load( open( fh , \"rb\" ) )\n",
        "    for row in matrix:\n",
        "        image = row.reshape(224,224,3)  \n",
        "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (size[1], size[0]))\n",
        "        # update the data and labels lists, respectively\n",
        "        data.append(image)\n",
        "        labels.append(label)\n",
        "        \n",
        "    matrix=None\n",
        "\n",
        "\n",
        "data = np.array(data)/255.0\n",
        "labels = np.array(labels)\n",
        "ind=np.random.permutation(labels.size)\n",
        "data=data[ind,:]\n",
        "labels=labels[ind]\n",
        "print(\"[INFO] data matrix: {:.2f}MB\".format(data.nbytes / (1024 * 1000.0)))\n",
        "print(data.shape)\n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "LB = lb.fit_transform(labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7salaEGpgAyA"
      },
      "source": [
        "#show some examples\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.subplot(221)\n",
        "index = 50\n",
        "img = data[index] \n",
        "plt.imshow(img);    # plot the image\n",
        "plt.axis('off');\n",
        "plt.title(labels[index])\n",
        "\n",
        "plt.subplot(222)\n",
        "index = 300\n",
        "img = data[index] \n",
        "plt.imshow(img);    # plot the image\n",
        "plt.axis('off');\n",
        "plt.title(labels[index])\n",
        "\n",
        "plt.subplot(223)\n",
        "index = 500\n",
        "img = data[index] \n",
        "plt.imshow(img);    # plot the image\n",
        "plt.axis('off');\n",
        "plt.title(labels[index])\n",
        "\n",
        "plt.subplot(224)\n",
        "index = 700\n",
        "img = data[index] \n",
        "plt.imshow(img);    # plot the image\n",
        "plt.axis('off');\n",
        "plt.title(labels[index])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7RPuUS0f2Jq"
      },
      "source": [
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\tLB, test_size=0.2, random_state=42, shuffle=True)\n",
        "# construct the image generator for data augmentation\n",
        "#aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "#\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "#\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,fill_mode=\"nearest\")\n",
        "\n",
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = SmallerVGGNet.build(width=size[1], height=size[0],\n",
        "\tdepth=size[2], classes=len(lb.classes_))\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\tx=aug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oIAHzvpSzzm"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        " target_names=lb.classes_))\n",
        "\n",
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
        "total = sum(sum(cm))\n",
        "\n",
        "# show the confusion matrix\n",
        "print(cm)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9PAWWWOJZlf"
      },
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "\n",
        "file_name = model_dir + 'May_24_vgg_small.h5'\n",
        "\n",
        "model.save(file_name, save_format='h5')\n",
        "\n",
        "# save the label binarizer to disk\n",
        "print(\"[INFO] serializing label binarizer...\")\n",
        "file_name = model_dir + 'hand_label_bin.p'\n",
        "\n",
        "f = open(file_name, \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJfUKpsGXeUO"
      },
      "source": [
        "lb.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR_tUQcZS0SC"
      },
      "source": [
        ""
      ]
    }
  ]
}